\section{Conclusion and Discussion}
We are proud of our work on this project and our final result of $81.7\%$ accuracy. In addition, this project deepened our knowledge of and familiarity with deep convolutional neural networks. We synthesized the research results regarding AlexNet discussed in class and applied them in a new context. In addition, our experiments made it clear to us that regularization can be the difference between an overfit network and an effective classifier.

If we had more time, we would have trained our network on the full dataset and submitted our network to Kaggle. The subset of data that we used takes several hours to download using Yale wifi. It would have been interesting to  write code so that several CPUs download (in parallel) the terabytes of images in the full dataset. In this case, we would have also trained our network using multiple GPUs. In addition, it would have been interesting to compete in the landmark image retrieval challenge as well. However, we found that working with ~50GB of data was more than enough for us to gain valuable experience with deep learning and convolutional neural networks.